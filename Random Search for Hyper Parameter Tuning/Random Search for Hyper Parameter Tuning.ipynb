{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "824c9ff2",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <h1 align=\"center\">Random Search for Hyper Parameter Tuning</h1>\n",
    "    <h3 align=\"center\"> Tabular Time Series</h3>\n",
    "    <h5 align=\"center\">Github: (https://github.com/MTisMT)</h5>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64d6d163",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import requests\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from scipy import stats\n",
    "from scipy.stats.mstats import spearmanr\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "plt.style.use(\"seaborn\")\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    " \n",
    "import tensorflow as tf\n",
    "from keras import optimizers\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from keras.layers import Dense, Dropout, Input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e413349f",
   "metadata": {},
   "source": [
    "# Time series cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e84762d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TS_crossval_block(X,y,k=5):\n",
    "    wsize = X.shape[0]//(k+1)\n",
    "    train_lb = 0\n",
    "    train_ub = train_lb + wsize\n",
    "    X_train={}; y_train={}\n",
    "    X_test={}; y_test={}\n",
    "    for i in range(1,k):\n",
    "        train_ub = train_lb + wsize\n",
    "        X_train[i] = X[train_lb:train_ub]; y_train[i] = y[train_lb:train_ub]\n",
    "        X_test[i] = X[train_ub:train_ub + wsize]; y_test[i] = y[train_ub:train_ub + wsize]\n",
    "        train_lb += wsize\n",
    "    \n",
    "    train_ub = train_lb + wsize\n",
    "    X_train[i+1] = X[train_lb:train_ub]; y_train[i+1] = y[train_lb:train_ub]\n",
    "    X_test[i+1] = X[train_ub:]; y_test[i+1] = y[train_ub:]\n",
    "    return X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d519e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TS_crossval(X,y,k=5):\n",
    "    wsize = X.shape[0]//(k+1)\n",
    "    train_lb = 0\n",
    "    train_ub = train_lb + wsize\n",
    "    X_train={}; y_train={}\n",
    "    X_test={}; y_test={}\n",
    "    for i in range(1,k):\n",
    "        #train_ub = train_lb + wsize\n",
    "        X_train[i] = X[train_lb:train_ub]; y_train[i] = y[train_lb:train_ub]\n",
    "        X_test[i] = X[train_ub:train_ub + wsize]; y_test[i] = y[train_ub:train_ub + wsize]\n",
    "        train_ub += wsize\n",
    "    \n",
    "    X_train[i+1] = X[train_lb:train_ub]; y_train[i+1] = y[train_lb:train_ub]\n",
    "    X_test[i+1] = X[train_ub:]; y_test[i+1] = y[train_ub:]\n",
    "    return X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75f0e0a",
   "metadata": {},
   "source": [
    "# Score of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "538dd7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scorer(y_test, y_pred):\n",
    "    # Can be any score based on the problem\n",
    "    score = (stats.spearmanr(y_test, y_pred))[0]\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce2f51e",
   "metadata": {},
   "source": [
    "# Deep Learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14072fd5",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39a95488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ANN_model(X,y,X_t,y_t,lr=0.005,bs=100, ep=10, actv='relu',\n",
    "                  min_lr=0.00001, f_lr=0.2, reg=0,h_layers=2):\n",
    "    #X=AE_r.predict(X)\n",
    "    #X_t=AE_r.predict(X_t)\n",
    "    score={}\n",
    "    input_sz=X.shape[1]\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(input_sz,)))\n",
    "    #model.add(Dropout(0.1))\n",
    "    model.add(Dense(1000,activation=actv, kernel_regularizer=regularizers.l1_l2(l1=reg, l2=reg),\n",
    "                    bias_regularizer=regularizers.l2(reg)))\n",
    "    model.add(Dropout(0.3))\n",
    "    for h_layer in range(h_layers+1):\n",
    "        model.add(Dense(1000,activation=actv, kernel_regularizer=regularizers.l1_l2(l1=reg, l2=reg),\n",
    "                        bias_regularizer=regularizers.l2(reg)))\n",
    "        model.add(Dropout(0.3))\n",
    "        \n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(1,activation='linear'))\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    #opt = tf.keras.optimizers.SGD(learning_rate=lr, momentum=0.9)\n",
    "    model.compile(optimizer=opt,loss='mse')\n",
    "    ES = EarlyStopping(monitor='loss', restore_best_weights=True, patience=7)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=f_lr,\n",
    "                              patience=5, min_lr=min_lr)\n",
    "    model.hist = model.fit(X,y,epochs=ep, callbacks=[ES,reduce_lr],\n",
    "              validation_data=(X_t,y_t),shuffle=False, batch_size=bs,verbose=1)\n",
    "    score['train_score'] = scorer(y,model.predict(X)[:,0])\n",
    "    score['test_score'] = scorer(y_t,model.predict(X_t)[:,0])\n",
    "    \n",
    "    return model, score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9746f0c0",
   "metadata": {},
   "source": [
    "# Conv ML model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b1c96d",
   "metadata": {},
   "source": [
    "## XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c05c2bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xg_boost_r(X_train, y_train,X_test=None ,y_test=None,n_est=300,lr=0.001,max_d=2,subcols=0.5,min_leaf=3):\n",
    "    \n",
    "    model = xgb.XGBRegressor(objective='reg:squarederror', max_depth=max_d, learning_rate=lr,\n",
    "                          n_estimators=n_est, n_jobs=-1, colsample_bytree=subcols,min_child_weight=min_leaf)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    pred_train = model.predict(X_train)\n",
    "    model.train_score=scorer(y_train, pred_train)\n",
    "    if X_test is not None and y_test is not None:\n",
    "        pred_test = model.predict(X_test)\n",
    "        model.test_score=scorer(y_test, pred_test)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c373fb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lightgbm_r(X_train, y_train,X_test=None ,y_test=None,n_est=300,lr=0.01,max_d=2,subcols=0.5,min_leaf=31):\n",
    "    \n",
    "    model = lgb.LGBMRegressor(max_depth=max_d, learning_rate=lr,\n",
    "                          n_estimators=n_est, colsample_bytree=subcols,num_leaves=min_leaf)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    pred_train = model.predict(X_train)\n",
    "    model.train_score=scorer(y_train, pred_train)\n",
    "    if X_test is not None and y_test is not None:\n",
    "        pred_test = model.predict(X_test)\n",
    "        model.test_score=scorer(y_test, pred_test)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f3b6e3",
   "metadata": {},
   "source": [
    "# Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "422a789e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_search(params,ratio=0.2):\n",
    "    p = list(params.values())\n",
    "    t = []\n",
    "    for r in itertools.product(*p): t.append([*r])\n",
    "    num = int(ratio * len(t))\n",
    "    random_locs = np.random.permutation(len(t))[:num]\n",
    "    print(num,\"sets of parameters has randomly selected among\", len(t), \"possible sets\")\n",
    "    return [t[i] for i in list(random_locs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a6632d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 sets of parameters has randomly selected among 160 possible sets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0.05, 10, 0, 64],\n",
       " [0.001, 2, 2, 64],\n",
       " [0.01, 20, 4, 64],\n",
       " [0.01, 50, 2, 64],\n",
       " [0.05, 2, 1, 64],\n",
       " [0.01, 10, 0, 32],\n",
       " [0.01, 20, 2, 32],\n",
       " [0.0001, 20, 1, 64],\n",
       " [0.01, 50, 0, 32],\n",
       " [0.001, 10, 4, 32],\n",
       " [0.0001, 10, 0, 32],\n",
       " [0.0001, 50, 1, 32],\n",
       " [0.01, 20, 1, 64],\n",
       " [0.05, 20, 2, 64],\n",
       " [0.0001, 10, 1, 32],\n",
       " [0.0001, 5, 2, 32],\n",
       " [0.001, 10, 0, 64],\n",
       " [0.0001, 50, 4, 32],\n",
       " [0.001, 50, 4, 32],\n",
       " [0.0001, 20, 2, 32],\n",
       " [0.05, 50, 2, 64],\n",
       " [0.01, 5, 0, 64],\n",
       " [0.05, 10, 4, 64],\n",
       " [0.001, 20, 1, 64],\n",
       " [0.0001, 20, 4, 64],\n",
       " [0.05, 50, 2, 32],\n",
       " [0.001, 2, 2, 32],\n",
       " [0.0001, 20, 4, 32],\n",
       " [0.0001, 5, 4, 64],\n",
       " [0.001, 20, 2, 32],\n",
       " [0.001, 50, 1, 32],\n",
       " [0.05, 2, 1, 32]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'lr': [0.05,0.01,0.001,0.0001], \n",
    "           'ep':[2,5,10,20,50],\n",
    "           'h_layer':[0,1,2,4],\n",
    "           'bs':[32,64]}\n",
    "\n",
    "param_cml={'subcols':[0.3,0.5,0.9], \n",
    "           'max_d':[2,3,5,7,10,15,None],\n",
    "           'lr': [0.5,0.1,0.01,0.05,0.001,0.0001],\n",
    "           'min_l': [10,20]}\n",
    "\n",
    "random_search(params,ratio=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4959bc5b",
   "metadata": {},
   "source": [
    "# Tune Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a149096",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Tune_model(data, params, ANN= True,random_ratio = 0.2 ,model_name='model', folds=5):\n",
    "    \n",
    "    X_train = data['X_train']\n",
    "    X_test = data['X_test']\n",
    "    y_train = data['y_train']\n",
    "    y_test = data['y_test']\n",
    "    \n",
    "    if ANN:\n",
    "        random_parameters = random_search(params,ratio=0.2)\n",
    "    else:\n",
    "        random_parameters = random_search(params,ratio=0.2)\n",
    "\n",
    "    Grid_cv=pd.DataFrame(columns=params.keys())\n",
    "    Grid_cv['test_score_mean']=np.nan\n",
    "    Grid_cv['test_score_std']=np.nan\n",
    "    Grid_cv['train_score_mean']=np.nan\n",
    "    Grid_cv['train_score_std']=np.nan\n",
    "    for k in range(1,folds+1):\n",
    "        Grid_cv[f'test_score_{k}']=np.nan\n",
    "    for k in range(1,folds+1):\n",
    "        Grid_cv[f'train_score_{k}']=np.nan\n",
    "\n",
    "    #####TUNE Classic ML Model ######\n",
    "    if not ANN:\n",
    "        print(len(random_parameters),' models each in' , len(X_train) , 'time series cross validation ...')\n",
    "\n",
    "        i=1\n",
    "        counter = 0\n",
    "        for subcols,max_d,lr,min_l in random_parameters:\n",
    "            counter +=1\n",
    "            test_score=[]\n",
    "            train_score=[]\n",
    "            for k in range(1,folds+1):\n",
    "                print(counter,'HyperParam set', 'in', k,'crossval fold')\n",
    "\n",
    "                model_F_r= lightgbm_r(X_train[k],y_train[k],X_test[k],y_test[k],\n",
    "                                        n_est=500,lr=lr,max_d=max_d,subcols=subcols,min_leaf=min_l)\n",
    "\n",
    "                test_score.append(model_F_r.test_score)\n",
    "                train_score.append(model_F_r.train_score)\n",
    "                   \n",
    "            Grid_cv.loc[i]=[subcols, max_d, lr,np.mean(test_score),np.std(test_score),\n",
    "                            np.mean(train_score),np.std(train_score),\n",
    "                           *test_score,*train_score]\n",
    "            i+=1\n",
    "        print('Done!')\n",
    "    if ANN:\n",
    "        print(len(random_parameters),' models each in' , len(X_train) , 'time series cross validation ...')\n",
    "        i=1\n",
    "        counter = 0\n",
    "        for lr,ep,h_lr,bs in random_parameters:\n",
    "            counter +=1\n",
    "            test_score=[]\n",
    "            train_score=[]\n",
    "            for k in range(1,folds+1):\n",
    "                print(counter,'HyperParam set', 'in', k,'crossval fold')\n",
    "\n",
    "                model_F_r,score = ANN_model(X_train[k],y_train[k],X_test[k],y_test[k],\n",
    "                                      lr=lr,bs=bs, ep=ep, actv='relu',min_lr=0.00001,\n",
    "                                      f_lr=0.2, reg=0, h_layers=h_lr)\n",
    "\n",
    "                test_score.append(score['test_score'])\n",
    "                train_score.append(score['train_score'])\n",
    "                    \n",
    "            Grid_cv.loc[i]=[lr, ep, h_lr, bs,np.mean(test_score),np.std(test_score),\n",
    "                            np.mean(train_score),np.std(train_score),\n",
    "                           *test_score,*train_score]\n",
    "            i+=1\n",
    "        print('Done!')\n",
    "        \n",
    "    return Grid_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0f1b9f",
   "metadata": {},
   "source": [
    "# Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f52d06b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#folds=4\n",
    "#sub_sample = 200\n",
    "#X_train,X_test,y_train,y_test=TS_crossval_block(train_data[:sub_sample],train_targets[:sub_sample],k=folds) #Sub\n",
    "#X_train,X_test,y_train,y_test=TS_crossval_block(train_data,train_targets,k=folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4b3be88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data={'X_train': X_train, 'X_test': X_test,\n",
    " #     'y_train': y_train, 'y_test': y_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d421d344",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid_cv_r = Tune_model(data, param = param_ann, ANN= True, random_ratio = 0.2 , model_name='ANN', folds = folds)\n",
    "#Grid_cv_r.to_csv('tune_random_search_r.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc616b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
